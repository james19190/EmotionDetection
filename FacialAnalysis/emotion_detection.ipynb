{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccesary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model = MobileNet(input_shape=(224,224,3), include_top=False)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "X = Flatten()(model.output)\n",
    "X = Dense(units= 7, activation='softmax')(X)\n",
    "\n",
    "model = Model(model.input, X)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Preprocessing Train Data\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    zoom_range = 0.2,\n",
    "    shear_range= 0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory='../FacialAnalysis/TrainData/',\n",
    "    target_size=(224,224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(train_data.class_indices)\n",
    "\n",
    "\n",
    "# Preprocessing Validation Data\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    directory='../FacialAnalysis/TestData/',\n",
    "    target_size=(224,224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(val_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    directory='../FacialAnalysis/TestData/',\n",
    "    target_size=(224,224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_data.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualization\n",
    "\n",
    "t_img , label = train_data.next()\n",
    "\n",
    "def plotImages(img_arr, label):\n",
    "  \"\"\"\n",
    "  input  :- images array \n",
    "  output :- plots the images \n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  for im, l in zip(img_arr,label) :\n",
    "    plt.imshow(im)\n",
    "    plt.title(im.shape)\n",
    "    plt.axis = False\n",
    "    plt.show()\n",
    "    \n",
    "    count += 1\n",
    "    if count == 10:\n",
    "      break\n",
    "\n",
    "plotImages(t_img, label)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
    "\n",
    "# model check point\n",
    "mc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "\n",
    "# puting call back in a list \n",
    "call_back = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_data, \n",
    "                           steps_per_epoch= 10, \n",
    "                           epochs= 30, \n",
    "                           validation_data= val_data, \n",
    "                           validation_steps= 8, \n",
    "                           callbacks=[es,mc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
